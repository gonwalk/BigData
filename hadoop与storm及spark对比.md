## [spark与storm的对比](http://www.cnblogs.com/yaohaitao/p/5703288.html)

| 对比点 | Storm | Spark Streaming |
| :--- | :--- | :--- |
| 实时计算模型 | 纯实时，来一条数据，处理一条数据 | 准实时，对一个时间段内的数据收集起来，作为一个RDD，再处理 |
| 实时计算延迟度 | 毫秒级 | 秒级 |
| 吞吐量 | 低 | 高 |
| 事务机制 | 支持完善 | 支持，但不够完善 |
| 健壮性 / 容错性 | ZooKeeper，Acker，非常强 | Checkpoint，WAL，一般 |
| 动态调整并行度 | 支持 | 不支持 |

## ** Spark Streaming与Storm的应用场景**

对于Storm来说：  
1、建议在那种需要纯实时，不能忍受1秒以上延迟的场景下使用，比如**实时金融系统，要求纯实时进行金融交易和分析**  
2、此外，如果对于实时计算的功能中，要求**可靠的事务机制和可靠性机制**，即数据的处理完全精准，一条也不能多，一条也不能少，也可以考虑使用Storm  
3、如果还需要针对高峰低峰时间段，**动态调整实时计算程序的并行度，以最大限度充分利用集群资源**（通常是在小型公司，集群资源紧张的情况），也可以考虑用Storm  
4、如果一个大数据应用系统，它就是纯粹的实时计算，不需要在中间执行SQL交互式查询、复杂的transformation算子等，那么用Storm是比较好的选择

对于Spark Streaming来说：  
1、如果对上述适用于Storm的三点，一条都不满足的实时场景，即，不要求纯实时，不要求强大可靠的事务机制，不要求动态调整并行度，那么可以考虑使用Spark Streaming  
2、考虑使用Spark Streaming最主要的一个因素，应该是**针对整个项目进行宏观的考虑**，即，如果一个项目除了实时计算之外，还**包括了离线批处理、交互式查询**等业务功能，而且实时计算中，可能还会牵扯到**高延迟批处理、交互式查询等功能**，那么就应该**首选Spark生态，用Spark Core开发离线批处理，用Spark SQL开发交互式查询，用Spark Streaming开发实时计算，三者可以无缝整合，给系统提供非常高的可扩展性**

## ** Spark Streaming与Storm的优劣分析**

事实上，Spark Streaming绝对谈不上比Storm优秀。这两个框架在实时计算领域中，都很优秀，只是擅长的细分场景并不相同。

Spark Streaming仅仅在吞吐量上比Storm要优秀，而吞吐量这一点，也是历来挺Spark Streaming，贬Storm的人着重强调的。但是问题是，是不是在所有的实时计算场景下，都那么注重吞吐量？不尽然。因此，通过吞吐量说Spark Streaming强于Storm，不靠谱。

事实上，Storm在实时延迟度上，比Spark Streaming就好多了，前者Storm是纯实时，后者Spark Streaming是准实时。而且，Storm的事务机制、健壮性 / 容错性、动态调整并行度等特性，都要比Spark Streaming更加优秀。

Spark Streaming，有一点是Storm绝对比不上的，就是：它位于Spark生态技术栈中，因此**Spark Streaming可以和Spark Core、Spark SQL无缝整合，也就意味着，我们可以对实时处理出来的中间数据，立即在程序中无缝进行延迟批处理、交互式查询等操作。这个特点大大增强了Spark Streaming的优势和功能。**

# hadoop、storm和spark的区别、比较

2016年11月05日 21:28:05

收藏自     [http://blog.csdn.net/bitcarmanlee/article/details/53047984](http://blog.csdn.net/bitcarmanlee/article/details/53047984)

## 1、hadoop、Storm该选哪一个？ {#1hadoopstorm该选哪一个}

为了区别hadoop和Storm，该部分将回答如下问题：  
1.hadoop、Storm各是什么运算  
2.Storm为什么被称之为流式计算系统  
3.hadoop适合什么场景，什么情况下使用hadoop  
4.什么是吞吐量

首先整体认识：**Hadoop是磁盘级计算，进行计算时，数据在磁盘上，需要读写磁盘；Storm是内存级计算，数据直接通过网络导入内存。读写内存比读写磁盘速度快n个数量级。**根据Harvard CS61课件，磁盘访问延迟约为内存访问延迟的75000倍。所以Storm更快。

注释：  
**1. 延时 ， 指数据从产生到运算产生结果的时间，“快”应该主要指这个。  
2. 吞吐， 指系统单位时间处理的数据量。**

### 从时延角度来讲：

storm的网络直传、内存计算，其时延必然比hadoop的通过hdfs传输低得多；当计算模型比较适合流式时，storm的流式处理，省去了批处理的收集数据的时间；因为storm是服务型的作业，也省去了作业调度的时延。所以**从时延上来看，storm要快于hadoop。**

### 从原理角度来讲：

**Hadoop M/R基于HDFS，需要切分输入数据、产生中间数据文件、排序、数据压缩、多份复制等，效率较低。  
Storm 基于ZeroMQ这个高性能的消息通讯库，不持久化数据。**

为什么storm比hadoop快，下面举一个应用场景  
说一个典型的场景，几千个日志生产方产生日志文件，需要进行一些ETL操作存入一个数据库。

假设利用hadoop，则需要先存入hdfs，按每一分钟切一个文件的粒度来算（这个粒度已经极端的细了，再小的话hdfs上会一堆小文件），hadoop开始计算时，1分钟已经过去了，然后再开始调度任务又花了一分钟，然后作业运行起来，假设机器特别多，几钞钟就算完了，然后写数据库假设也花了很少的时间，这样，从数据产生到最后可以使用已经过去了至少两分多钟。  
而Storm**流式计算在数据产生时，则有一个程序去一直监控日志的产生，产生一行就通过一个传输系统发给流式计算系统，然后流式计算系统直接处理，处理完之后直接写入数据库，每条数据从产生到写入数据库，在资源充足时可以在毫秒级别完成。**

同时说一下另外一个场景：  
如果一个大文件的wordcount，把它放到storm上进行流式的处理，等已有的所有数据处理完才让storm输出结果，这时候，你再把它和hadoop比较快慢，这时，其实比较的不是时延，而是比较的吞吐了。

---

**最主要的方面：Hadoop使用磁盘作为中间交换的介质，而storm的数据是一直在内存中流转的。  
两者面向的领域也不完全相同，一个（Hadoop）是批量处理，基于任务调度的；另外一个（Storm）是实时处理，基于流。**  
以水为例，Hadoop可以看作是纯净水，一桶桶地搬；而Storm是用水管，预先接好（Topology：拓扑结构），然后打开水龙头，水就源源不断地流出来了。

Storm的主工程师Nathan Marz表示： **Storm可以方便地在一个计算机集群中编写与扩展复杂的实时计算，Storm之于实时处理，就好比Hadoop之于批处理。Storm保证每个消息都会得到处理，而且它很快——在一个小集群中，每秒可以处理数以百万计的消息。更棒的是你可以使用任意编程语言来做开发。**

### Storm的主要特点如下：

1.**简单的编程模型**。类似于MapReduce降低了并行批处理复杂性，Storm降低了进行实时处理的复杂性。  
2.**可以使用各种编程语言**。你可以在Storm之上使用各种编程语言。默认支持Clojure、Java、Ruby和Python。要增加对其他语言的支持，只需实现一个简单的Storm通信协议即可。  
3.**容错性。Storm会管理工作进程和节点的故障。**  
4.**水平扩展。计算是在多个线程、进程和服务器之间并行进行的。**  
5.**可靠的消息处理**。Storm保证每个消息至少能得到一次完整处理。任务失败时，它会负责从消息源重试消息。  
6.快速。系统的设计保证了消息能得到快速的处理，使用MQ作为其底层消息队列。  
7.本地模式。Storm有一个“本地模式”，可以在处理过程中完全模拟Storm集群。这让你可以快速进行开发和单元测试。

在消耗资源相同的情况下，一般来说storm的延时低于mapreduce。但是吞吐也低于mapreduce。storm是典型的流计算系统，mapreduce是典型的批处理系统。

对流计算和批处理系统流程来说大致可以分三个阶段：  
1. 数据采集与准备  
2. 数据计算（涉及计算中的中间存储）  
3. 数据结果展现（反馈）

1）数据采集阶段，目前典型的处理策略：数据的产生系统一般出自页面打点和解析DB的log，流计算将数据采集中消息队列（比如kafaka,metaQ,timetunle）等。批处理系统一般将数据采集进分布式文件系统（比如HDFS），当然也有使用消息队列的。我们暂且把消息队列和文件系统称为预处理存储。二者在延时和吞吐上没太大区别，接下来从这个预处理存储进入到数据计算阶段有很大的区别，流计算一般在实时的读取消息队列，对于进入流计算系统（storm）的数据进行运算，批处理系统一般会攒一大批后批量导入到计算系统（hadoop），这里就有了延时的区别。  
2）数据计算阶段，流计算系统（storm）的延时低，主要有一下几个方面（针对题主的问题）  
A： storm 进程是常驻的，有数据就可以进行实时的处理  
mapreduce 数据攒一批后由作业管理系统启动任务，Jobtracker计算任务分配，tasktacker启动相关的运算进程  
B： stom每个计算单元之间，数据之间通过网络（zeromq）直接传输。  
mapreduce 中的map任务运算的结果要写入到HDFS，对于reduce任务通过网络拖过去运算。相对来说多了磁盘读写，比较慢  
C： 对于复杂运算  
**storm的运算模型直接支持DAG（有向无环图）  
mapreduce 需要多个MR过程，有些map操作没有意义**

3）数据结果展现  
**流计算一般运算结果直接反馈到最终结果集中（展示页面，数据库，搜索引擎的索引）。而mapreduce一般需要整个运算结束后将结果批量导入到结果集中。**

实际流计算和批处理系统没有本质的区别，像storm的trident也有批概念，而mapreduce可以将每次运算的数据集缩小（比如几分钟启动一次），facebook的puma就是基于hadoop做的流计算系统。

## 2、高性能并行计算引擎Storm和Spark比较 {#2高性能并行计算引擎storm和spark比较}

**Spark基于这样的理念，当数据庞大时，把计算过程传递给数据要比把数据传递给计算过程要更富效率。每个节点存储（或缓存）它的数据集，然后任务被提交给节点。所以这是把过程传递给数据。**这和Hadoop map/reduce非常相似，除了积极使用内存来避免I/O操作，以使得迭代算法（前一步计算输出是下一步计算的输入）性能更高。  
Shark只是一个基于Spark的查询引擎（支持ad-hoc临时性的分析查询）  
而Storm的架构和Spark截然相反。**Storm是一个分布式流计算引擎。每个节点实现一个基本的计算过程，而数据项在互相连接的网络节点中流进流出（把数据传递给过程，即节点，因为Storm的每个节点实现一个基本的计算过程）**。和Spark相反，这个是把数据传递给过程。**简单来说，Spark是把过程传递给数据，而Storm是把数据传递给过程。**  
两个框架都用于处理大量数据的并行计算。  
**Storm在动态处理大量生成的“小数据块”上要更好（比如在Twitter数据流上实时计算一些汇聚功能或分析）。  
Spark工作于现有的数据全集（如Hadoop数据）已经被导入Spark集群，Spark基于in-memory管理可以进行快速扫描，并最小化迭代算法的全局I/O操作。**  
不过Spark流模块（Streaming Module）倒是和Storm相类似（都是流计算引擎），尽管并非完全一样。  
Spark流模块先汇聚批量数据然后进行数据块分发（视作不可变数据进行处理），而Storm是只要接收到数据就实时处理并分发。  
不确定哪种方式在数据吞吐量上要具优势，不过Storm计算时间延迟要小。  
**总结下，Spark和Storm设计相反，而Spark Steaming才和Storm类似，前者有数据平滑窗口（sliding window），而后者需要自己去维护这个窗口。**

